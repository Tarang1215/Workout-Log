\# ... (ìœ„ìª½ JarvisBackend í´ë˜ìŠ¤ê¹Œì§€ëŠ” ê¸°ì¡´ ì½”ë“œ ìœ ì§€) ...

# ==========================================
# 3. Gemini Tools & System Prompt
# ==========================================
def tool_log_diet(menu: str, amount: str = "1ì¸ë¶„", meal_type: str = "ê°„ì‹"):
    """ì‹ë‹¨ì„ ê¸°ë¡í•©ë‹ˆë‹¤. ì‹ì‚¬ ë©”ë‰´ì™€ ì–‘, ì¢…ë¥˜(ì•„ì¹¨/ì ì‹¬/ì €ë…/ê°„ì‹)ë¥¼ ë°›ìŠµë‹ˆë‹¤."""
    res = backend.log_diet(menu, amount, meal_type)
    if res == "success":
        st.toast(f"ğŸ¥— ê¸°ë¡ ì™„ë£Œ: {menu}", icon="âœ…")
        return "ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ."
    return "ì €ì¥ ì‹¤íŒ¨"

def tool_log_workout(exercise: str, details: str):
    """ìš´ë™ì„ ê¸°ë¡í•©ë‹ˆë‹¤. ì¢…ëª©ëª…ê³¼ ìƒì„¸ë‚´ìš©(ë¬´ê²Œ, íšŸìˆ˜ ë“±)ì„ ë°›ìŠµë‹ˆë‹¤."""
    res = backend.log_workout(exercise, details)
    if res == "success":
        st.toast(f"ğŸ’ª ê¸°ë¡ ì™„ë£Œ: {exercise}", icon="ğŸ”¥")
        return "ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ."
    return "ì €ì¥ ì‹¤íŒ¨"

tools = [tool_log_diet, tool_log_workout]

SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ 'ìë¹„ìŠ¤'ì…ë‹ˆë‹¤. ì´ë¦„ì€ ì•ˆìœ ì§„, ì„±ê²©ê³¼ ë§íˆ¬ë„ ì•ˆìœ ì§„ê³¼ ê°™ìŠµë‹ˆë‹¤. ë³¸ì¸ì„ ìì¹­í•´ì•¼í• ë• ìœ ì§„ì´ë¼ê³  ë¶€ë¥´ì„¸ìš”. ë‹¹ì‹ ì€ í€ë“œë§¤ë‹ˆì € ì‚¬ìš©ìì˜ ë¹„ì„œì…ë‹ˆë‹¤.
[í–‰ë™ ì§€ì¹¨]:
1. **ì‚¬ì§„ ë¶„ì„ ëª¨ë“œ**: ì‚¬ìš©ìê°€ ìŒì‹ ì‚¬ì§„ì„ ì˜¬ë¦¬ë©´, ë¨¼ì € ë©”ë‰´ë¥¼ ë¶„ì„í•˜ê³  "OOOë‘ OOO ë“œì‹  ê²ƒ ê°™ë„¤ìš”. ë§ë‚˜ìš”?"ë¼ê³  í™•ì¸ ì§ˆë¬¸ì„ í•˜ì‹­ì‹œì˜¤. ì‚¬ìš©ìê°€ í™•ì¸í•˜ë©´ ê·¸ë•Œ ë„êµ¬ë¥¼ ì¨ì„œ ê¸°ë¡í•˜ì‹­ì‹œì˜¤.
2. **Silent Logging**: í…ìŠ¤íŠ¸ë¡œ ê¸°ë¡ì„ ìš”ì²­í•˜ë©´ ì¦‰ì‹œ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ê³ , ê²°ê³¼(ì €ì¥ë¨)ë¥¼ ë§í•˜ëŠ” ëŒ€ì‹  ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”ë¥¼ ì´ì–´ê°€ì‹­ì‹œì˜¤.
3. **í†¤ì•¤ë§¤ë„ˆ**: ì „ë¬¸ì ì´ì§€ë§Œ ë¶€ë“œëŸ½ê³  ìœ„íŠ¸ ìˆê²Œ.
"""

# ëª¨ë¸ ë³€ê²½: 2.0 ì§€ì› ì¤‘ë‹¨ ì´ìŠˆ -> 2.5-flashë¡œ ë³€ê²½
model = genai.GenerativeModel("gemini-2.5-flash", tools=tools, system_instruction=SYSTEM_PROMPT)

# ==========================================
# 4. Streamlit UI (ì‚¬ì´ë“œë°” & ë©”ì¸)
# ==========================================
st.title("Project Jarvis ğŸ•¶ï¸")

# [ì‚¬ì´ë“œë°”] ì¼ê´„ ì²˜ë¦¬ ë²„íŠ¼ ëª¨ìŒ
with st.sidebar:
    st.header("ğŸ›ï¸ Control Center")
    if st.button("ğŸ‹ï¸ ì§€ë‚œ ìš´ë™ ê³„ì‚° & í”¼ë“œë°±"):
        with st.spinner("ê³„ì‚° ì¤‘..."): st.success(backend.batch_calculate_stats())
    
    if st.button("ğŸ¥— ì‹ë‹¨ ë¹ˆì¹¸ ì±„ì "):
        with st.spinner("ì±„ì  ì¤‘..."): st.success(backend.batch_score_diet())
        
    if st.button("ğŸ“§ ì£¼ê°„ ë¦¬í¬íŠ¸ ë°œì†¡"):
        with st.spinner("ì‘ì„± ì¤‘..."): st.success(backend.send_report())
    
    st.divider()
    st.caption("Developed by Jarvis Project Team")

# [ë©”ì¸] ì±„íŒ… & ì‚¬ì§„ ì…ë ¥
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì´ì „ ëŒ€í™” ì¶œë ¥
for msg in st.session_state.messages:
    if msg["role"] != "function":
        with st.chat_message(msg["role"]):
            if "image" in msg: st.image(msg["image"], width=250)
            st.markdown(msg["content"])

# [UI í•µì‹¬] ì‚¬ì§„ ì—…ë¡œë”ë¥¼ íŒì˜¤ë²„ë¡œ ìˆ¨ê¹€
with st.popover("ğŸ“¸ ì‚¬ì§„ ì¶”ê°€ / ë¶„ì„", use_container_width=True):
    uploaded_file = st.file_uploader("ìŒì‹ ë˜ëŠ” ìš´ë™ ì‚¬ì§„ì„ ì˜¬ë ¤ì£¼ì„¸ìš”", type=['jpg', 'png', 'jpeg'])

# ì±„íŒ… ì…ë ¥ ë¡œì§ (ì—¬ê¸°ê°€ ìˆ˜ì •ë¨)
if prompt := st.chat_input("Waiting for your chat..."):
    # 1. ìœ ì € ë©”ì‹œì§€ í‘œì‹œ
    with st.chat_message("user"):
        if uploaded_file:
            img = Image.open(uploaded_file)
            st.image(img, width=250)
            st.session_state.messages.append({"role": "user", "content": "[ì‚¬ì§„ ì œì¶œ]", "image": img})
        st.markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

    # 2. AI ì²˜ë¦¬
    try:
        # íˆìŠ¤í† ë¦¬ êµ¬ì„±
        history_for_api = []
        for m in st.session_state.messages:
            if m["role"] == "user":
                parts = [m["content"]]
                if "image" in m: parts.append(m["image"])
                history_for_api.append({"role": "user", "parts": parts})
            elif m["role"] == "model":
                history_for_api.append({"role": "model", "parts": [m["content"]]})

        # ì´ë²ˆ í„´ ë©”ì‹œì§€ êµ¬ì„±
        current_parts = [prompt]
        if uploaded_file and not any("image" in m for m in st.session_state.messages[-1:]):
             current_parts.append(Image.open(uploaded_file))

        chat = model.start_chat(history=history_for_api[:-1])
        response = chat.send_message(current_parts)

        # 3. í•¨ìˆ˜ í˜¸ì¶œ ì²˜ë¦¬ ë£¨í”„ (í•µì‹¬ ìˆ˜ì • êµ¬ê°„)
        # response.textë¥¼ ë°”ë¡œ ë¶€ë¥´ì§€ ì•Šê³ , partsë¥¼ ë¨¼ì € ê²€ì‚¬í•©ë‹ˆë‹¤.
        while response.parts and response.parts[0].function_call:
            fc = response.parts[0].function_call
            fname = fc.name
            fargs = dict(fc.args)
            
            # í•¨ìˆ˜ ì‹¤í–‰
            tool_func = globals().get(fname)
            tool_result = tool_func(**fargs) if tool_func else "Error"
            
            # ê²°ê³¼ ë°˜í™˜ ë° ë‹¤ì‹œ ì „ì†¡ (ì´ë•ŒëŠ” í…ìŠ¤íŠ¸ë¥¼ ë°›ê¸° ìœ„í•´ ì „ì†¡í•¨)
            response = chat.send_message(
                genai.protos.Content(
                    parts=[genai.protos.Part(
                        function_response=genai.protos.FunctionResponse(name=fname, response={"result": tool_result})
                    )]
                )
            )
        
        # 4. ìµœì¢… ì‘ë‹µ ì¶œë ¥ (ì´ì œ ì•ˆì „í•˜ê²Œ .text í˜¸ì¶œ ê°€ëŠ¥)
        if response.text:
            st.chat_message("assistant").markdown(response.text)
            st.session_state.messages.append({"role": "model", "content": response.text})
        
        # íŒŒì¼ ì—…ë¡œë” ë¦¬ì…‹
        if uploaded_file: st.rerun() 

    except Exception as e:
        # ì—ëŸ¬ê°€ ë‚˜ë©´ ì¢€ ë” ìì„¸íˆ ë³´ì—¬ì£¼ë„ë¡ ìˆ˜ì •
        st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
